{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca824fc-127b-435f-8c2b-0a0253ec17d1",
   "metadata": {},
   "source": [
    "***\n",
    "# Model Deployment : Estimating Heart Failure Survival Risk Profiles From Cardiovascular, Hematologic And Metabolic Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87a39c-b8a3-429c-958c-fa629890307f",
   "metadata": {},
   "source": [
    "***\n",
    "### John Pauline Pineda <br> <br> *September 21, 2024*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f28c3ed-eef4-47e2-ac59-ff98b1dd9505",
   "metadata": {},
   "source": [
    "* [**1. Table of Contents**](#TOC)\n",
    "    * [1.1 Data Background](#1.1)\n",
    "    * [1.2 Data Description](#1.2)\n",
    "    * [1.3 Data Quality Assessment](#1.3)\n",
    "    * [1.4 Data Preprocessing](#1.4)\n",
    "    * [1.5 Data Exploration](#1.5)\n",
    "        * [1.5.1 Exploratory Data Analysis](#1.5.1)\n",
    "        * [1.5.2 Hypothesis Testing](#1.5.2)\n",
    "    * [1.6 Predictive Model Development](#1.6)\n",
    "        * [1.6.1 Pre-Modelling Data Preparation](#1.6.1)\n",
    "        * [1.6.2 Data Splitting](#1.6.2)\n",
    "        * [1.6.3 Modelling Pipeline Development](#1.6.3)\n",
    "        * [1.6.4 Semi-Parametric Model Fitting | Hyperparameter Tuning | Validation](#1.6.4)\n",
    "        * [1.6.5 Parametric Model Fitting | Hyperparameter Tuning | Validation](#1.6.5)\n",
    "        * [1.6.6 Model Selection](#1.6.7)\n",
    "        * [1.6.7 Model Testing](#1.6.8)\n",
    "        * [1.6.8 Model Inference](#1.6.9)\n",
    "    * [1.7 Predictive Model Deployment Using Streamlit and Streamlit Community Cloud](#1.7)\n",
    "        * [1.7.1 Model Prediction Application Code Development](#1.7.1)\n",
    "        * [1.7.2 Model Application Programming Interface Code Development](#1.7.2)\n",
    "        * [1.7.3 User Interface Application Code Development](#1.7.3)\n",
    "        * [1.7.4 Web Application](#1.7.4)\n",
    "* [**2. Summary**](#Summary)   \n",
    "* [**3. References**](#References)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a83df-a706-44a2-8d92-b2892610feca",
   "metadata": {},
   "source": [
    "# 1. Table of Contents <a class=\"anchor\" id=\"TOC\"></a>\n",
    "\n",
    "[Survival Analysis](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) deals with the analysis of time-to-event data. It focuses on the expected duration of time until one or more events of interest occur, such as death, failure, or relapse. This type of analysis is used to study and model the time until the occurrence of an event, taking into account that the event might not have occurred for all subjects during the study period. Several key aspects of survival analysis include the survival function which refers to the probability that an individual survives longer than a certain time, hazard function which describes the instantaneous rate at which events occur, given no prior event, and censoring pertaining to a condition where the event of interest has not occurred for some subjects during the observation period.\n",
    "\n",
    "[Right-Censored Survival Data](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) occurs when the event of interest has not happened for some subjects by the end of the study period or the last follow-up time. This type of censoring is common in survival analysis because not all individuals may experience the event before the study ends, or they might drop out or be lost to follow-up. Right-censored data is crucial in survival analysis as it allows the inclusion of all subjects in the analysis, providing more accurate and reliable estimates.\n",
    "\n",
    "[Survival Models](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) refer to statistical methods used to analyze survival data, accounting for censored observations. These models aim to describe the relationship between survival time and one or more predictor variables, and to estimate the survival function and hazard function. Survival models are essential for understanding the factors that influence time-to-event data, allowing for predictions and comparisons between different groups or treatment effects. They are widely used in clinical trials, reliability engineering, and other areas where time-to-event data is prevalent.\n",
    "\n",
    "[Cox Proportional Hazards Regression Models](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) relates the time until an event occurs (such as death or disease progression) to one or more predictor variables. The model is expressed through its hazard function, which represents the risk of the event happening at a particular time for an individual, given that the individual has survived up to that time. The mathematical equation is represented by the baseline hazard function (referring to the hazard for an individual when all of their covariates are zero, representing the inherent risk of the event happening over time, but is not directly estimated in the Cox model. Instead, the focus is on how the covariates influence the hazard relative to this baseline) and an exponential term that modifies the baseline hazard based on the individual's covariates (Each covariate is associated with a regression coefficient which measures the strength and direction of the effect of the covariate on the hazard. The exponential function ensures that the hazard is always positive, as hazard values can’t be negative). The proportional hazards assumption in this model means that the ratio of hazards between any two individuals is constant over time and is determined by the differences in their covariates. The Cox model doesn’t require a specific form for the baseline hazard, making it flexible, while properly accounting for censored data, which is common in survival studies.\n",
    "\n",
    "[Accelerated Failure Time Models](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) are a class of survival analysis models used to analyze time-to-event data by directly modelling the survival time itself. An AFT model assumes that the effect of covariates accelerates or decelerates the life time of an event by some constant factor. The mathematical equation is represented by the logarithm of the survival time being equal to the sum of the vector of covariates multiplied to the vector of regression coefficients; and the product of the scale parameter and a random variable with a specified distribution. In an AFT model, the coefficients represent the multiplicative effect on the survival time. An exponentiated regression coefficient greater than one prolongs survival time, while a value less than one shortens it. The scale parameter determines the spread or variability of survival times. AFT models assume that the effect of covariates on survival time is multiplicative and that the survival times can be transformed to follow a specific distribution.\n",
    "\n",
    "[Regularization Methods](http://appliedpredictivemodeling.com/), in the context of binary classification using Logistic Regression, are primarily used to prevent overfitting and improve the model's generalization to new data. Overfitting occurs when a model is too complex and learns not only the underlying pattern in the data but also the noise. This leads to poor performance on unseen data. Regularization introduces a penalty for large coefficients in the model, which helps in controlling the model complexity. In Logistic Regression, this is done by adding a regularization term to the loss function, which penalizes large values of the coefficients. This forces the model to keep the coefficients small, thereby reducing the likelihood of overfitting. Addiitonally, by penalizing the complexity of the model through the regularization term, regularization methods also help the model generalize better to unseen data. This is because the model is less likely to overfit the training data and more likely to capture the true underlying pattern.\n",
    "\n",
    "[Shapley Additive Explanations](https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) are based on Shapley values developed in the cooperative game theory. The process involves explaining a prediction by assuming that each explanatory variable for an instance is a player in a game where the prediction is the payout. The game is the prediction task for a single instance of the data set. The gain is the actual prediction for this instance minus the average prediction for all instances. The players are the explanatory variable values of the instance that collaborate to receive the gain (predict a certain value). The determined value is the average marginal contribution of an explanatory variable across all possible coalitions.\n",
    "\n",
    "[FastAPI](https://fastapi.tiangolo.com/) is a modern, fast (high-performance) web framework for building APIs with Python. It’s designed to make it easy to create APIs quickly, while still providing strong validation and type hints that improve both code quality and performance. FastAPI allows building APIs by defining endpoints, which are essentially routes that handle HTTP requests. Routes are defined in Python functions, and FastAPI takes care of handling the request, validating input data, and generating responses. Significant features include high performance (FastAPI is one of the fastest Python frameworks, comparable to Node.js and Go, making it ideal for production use, especially in applications that require low latency, such as machine learning model inference), asynchronous support (FastAPI natively supports asynchronous programming, which is great for handling multiple requests concurrently, improving performance in scenarios with high traffic), data validation (FastAPI automatically validates the data coming into the API based on type annotations. If the user sends incorrect data (e.g., wrong data type), FastAPI generates informative error messages), and auto-generated documentation (FastAPI automatically generates API documentation in both Swagger UI and ReDoc formats. This makes testing and understanding the created API simple and fast for developers and stakeholders). In the context of machine learning model deployment, FastAPI acts as the backend API that handles requests for predictions. When a client or application (like a frontend UI) sends data to the API, FastAPI passes it to the model, retrieves the model’s prediction, and sends the result back to the client.\n",
    "\n",
    "[Streamlit](https://streamlit.io/) is an open-source Python library that simplifies the creation and deployment of web applications for machine learning and data science projects. It allows developers and data scientists to turn Python scripts into interactive web apps quickly without requiring extensive web development knowledge. Streamlit seamlessly integrates with popular Python libraries such as Pandas, Matplotlib, Plotly, and TensorFlow, allowing one to leverage existing data processing and visualization tools within the application. Streamlit apps can be easily deployed on various platforms, including Streamlit Community Cloud, Heroku, or any cloud service that supports Python web applications.\n",
    "\n",
    "[Streamlit Community Cloud](https://streamlit.io/cloud), formerly known as Streamlit Sharing, is a free cloud-based platform provided by Streamlit that allows users to easily deploy and share Streamlit apps online. It is particularly popular among data scientists, machine learning engineers, and developers for quickly showcasing projects, creating interactive demos, and sharing data-driven applications with a wider audience without needing to manage server infrastructure. Significant features include free hosting (Streamlit Community Cloud provides free hosting for Streamlit apps, making it accessible for users who want to share their work without incurring hosting costs), easy deployment (users can connect their GitHub repository to Streamlit Community Cloud, and the app is automatically deployed from the repository), continuous deployment (if the code in the connected GitHub repository is updated, the app is automatically redeployed with the latest changes), \n",
    "sharing capabilities (once deployed, apps can be shared with others via a simple URL, making it easy for collaborators, stakeholders, or the general public to access and interact with the app), built-in authentication (users can restrict access to their apps using GitHub-based authentication, allowing control over who can view and interact with the app), and community support (the platform is supported by a community of users and developers who share knowledge, templates, and best practices for building and deploying Streamlit apps)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f673dd1c-3a5d-451a-941c-127b6cc56565",
   "metadata": {},
   "source": [
    "## 1.1. Data Background <a class=\"anchor\" id=\"1.1\"></a>\n",
    "\n",
    "An open [Heart Failure Dataset](https://paperswithcode.com/dataset/survival-analysis-of-heart-failure-patients) from [Papers With Code](https://paperswithcode.com/) (with all credits attributed to [Saurav Mishra](https://paperswithcode.com/search?q=author%3ASaurav+Mishra)) was used for the analysis as consolidated from the following primary source: \n",
    "1. Research Paper entitled **A Comparative Study for Time-to-Event Analysis and Survival Prediction for Heart Failure Condition using Machine Learning Techniques** from the [Journal of Electronics, Electromedical Engineering, and Medical Informatics](http://jeeemi.org/index.php/jeeemi/article/view/225/94)\n",
    "2. Research Paper entitled **Machine Learning Can Predict Survival of Patients with Heart Failure from Serum Creatinine and Ejection Fraction Alone** from the [BMC Medical Informatics and Decision Making](https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5) Journal\n",
    "\n",
    "This study hypothesized that cardiovascular, hematologic, and metabolic markers influence heart failure survival risks between patients.\n",
    "\n",
    "The event status and survival duration variables for the study are:\n",
    "* <span style=\"color: #FF0000\">DEATH_EVENT</span> - Status of the patient within the follow-up period (0, censored | 1, death)\n",
    "* <span style=\"color: #FF0000\">TIME</span> - Follow-up period\n",
    "\n",
    "The predictor variables for the study are:\n",
    "* <span style=\"color: #FF0000\">AGE</span> - Patient's age (Years)\n",
    "* <span style=\"color: #FF0000\">ANAEMIA</span> - Hematologic marker for the indication of anaemia (decrease of red blood cells or hemoglobin) (0, Absent | 1 Present)\n",
    "* <span style=\"color: #FF0000\">CREATININE_PHOSPHOKINASE</span> - Metabolic marker for the level of the CPK enzyme in the blood (mcg/L)\n",
    "* <span style=\"color: #FF0000\">DIABETES</span> - Metabolic marker for the indication of diabetes (0, Absent | 1 Present)\n",
    "* <span style=\"color: #FF0000\">EJECTION_FRACTION</span> - Cardiovascular marker for the ejection fraction (percentage of blood leaving the heart at each contraction) (%)\n",
    "* <span style=\"color: #FF0000\">HIGH_BLOOD_PRESSURE</span> - Cardiovascular marker for the indication of hypertension (0, Absent | 1 Present)\n",
    "* <span style=\"color: #FF0000\">PLATELETS</span> - Hematologic marker for the platelets in the blood (kiloplatelets/mL)\n",
    "* <span style=\"color: #FF0000\">SERUM_CREATININE</span> - Metabolic marker for level of creatinine in the blood (mg/dL)\n",
    "* <span style=\"color: #FF0000\">SERUM_SODIUM</span> - Metabolic marker for the level of sodium in the blood (mEq/L)\n",
    "* <span style=\"color: #FF0000\">SEX</span> - Patient's sex (0, Female | 1, Male)\n",
    "* <span style=\"color: #FF0000\">SMOKING</span> - Cardiovascular marker for the indication of smoking (0, Absent | 1 Present)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51551929-fe02-4d5b-9e6f-380bdfd1d746",
   "metadata": {},
   "source": [
    "## 1.2. Data Description <a class=\"anchor\" id=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57759e48-85e1-4e65-97b2-3dfd6b456a07",
   "metadata": {},
   "source": [
    "## 1.3. Data Quality Assessment <a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57175b-264f-49fc-8905-b3d47a476919",
   "metadata": {},
   "source": [
    "## 1.4. Data Preprocessing <a class=\"anchor\" id=\"1.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761b92d-3c44-41ce-80b8-3ccb2bc30ffb",
   "metadata": {},
   "source": [
    "## 1.5. Data Exploration <a class=\"anchor\" id=\"1.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea49440-5421-4ef7-ade6-b8b301929ece",
   "metadata": {},
   "source": [
    "### 1.5.1 Exploratory Data Analysis <a class=\"anchor\" id=\"1.5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730bfc1d-807d-450e-9285-ada4fd275c34",
   "metadata": {},
   "source": [
    "### 1.5.2 Hypothesis Testing <a class=\"anchor\" id=\"1.5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c0339-1141-4156-b025-b7ae7b6a8da0",
   "metadata": {},
   "source": [
    "## 1.6. Predictive Model Development <a class=\"anchor\" id=\"1.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002db35e-f23b-4b0c-8b40-9c18cad295d2",
   "metadata": {},
   "source": [
    "### 1.6.1 Pre-Modelling Data Preparation <a class=\"anchor\" id=\"1.6.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e51125-c662-47a6-aa98-c2a1d2eb6771",
   "metadata": {},
   "source": [
    "### 1.6.2 Data Splitting <a class=\"anchor\" id=\"1.6.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4494f8b-8905-427e-b8ec-641042729e94",
   "metadata": {},
   "source": [
    "### 1.6.3 Modelling Pipeline Development <a class=\"anchor\" id=\"1.6.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033cb0c-a6c4-4467-ad70-32bfb8a2ed84",
   "metadata": {},
   "source": [
    "### 1.6.4 Semi-Parametric Model Fitting | Hyperparameter Tuning | Validation <a class=\"anchor\" id=\"1.6.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa2163-598c-47be-b64e-794b27013cc1",
   "metadata": {},
   "source": [
    "### 1.6.5 Model Fitting using Original Training Data | Hyperparameter Tuning | Validation <a class=\"anchor\" id=\"1.6.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb216e-d02d-4df9-8a73-8108ffd76356",
   "metadata": {},
   "source": [
    "### 1.6.6 Model Selection <a class=\"anchor\" id=\"1.6.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1a60a-ea89-467c-9efd-70e3e15c6551",
   "metadata": {},
   "source": [
    "### 1.6.7 Model Testing <a class=\"anchor\" id=\"1.6.7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbdfaa5-75f0-40dc-9ca5-0d670ca5f560",
   "metadata": {},
   "source": [
    "### 1.6.8 Model Inference <a class=\"anchor\" id=\"1.6.8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d3a76-ee9e-4d78-8d46-a9f4f1be9ff2",
   "metadata": {},
   "source": [
    "## 1.7. Predictive Model Deployment Using Streamlit and Streamlit Community Cloud <a class=\"anchor\" id=\"1.7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3395d1-15de-4a20-a1b7-3e14185bd91a",
   "metadata": {},
   "source": [
    "### 1.7.1 Model Prediction Application Code Development <a class=\"anchor\" id=\"1.7.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451fd9e4-0290-4d33-bb0f-56058571d128",
   "metadata": {},
   "source": [
    "### 1.7.2 Model Application Programming Interface Code Development <a class=\"anchor\" id=\"1.7.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178d661-27e4-4714-8c4d-86f39f166081",
   "metadata": {},
   "source": [
    "### 1.7.3 User Interface Application Code Development <a class=\"anchor\" id=\"1.7.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ffe53-c63e-480d-87ff-486b571cc817",
   "metadata": {},
   "source": [
    "### 1.7.4 Web Application <a class=\"anchor\" id=\"1.7.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f27024-a6c6-46ae-8f1c-956913c2f4ff",
   "metadata": {},
   "source": [
    "# 2. Summary <a class=\"anchor\" id=\"Summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bb64a-4fc6-400f-829c-2c35ea91e9ea",
   "metadata": {},
   "source": [
    "# 3. References <a class=\"anchor\" id=\"References\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ef7c2-740e-4f3d-87ff-6d6368b610c5",
   "metadata": {},
   "source": [
    "\n",
    "* **[Book]** [Clinical Prediction Models](http://clinicalpredictionmodels.org/) by Ewout Steyerberg\n",
    "* **[Book]** [Survival Analysis: A Self-Learning Text](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) by David Kleinbaum and Mitchel Klein\n",
    "* **[Book]** [Applied Survival Analysis Using R](https://link.springer.com/book/10.1007/978-3-319-31245-3/) by Dirk Moore\n",
    "* **[Book]** [Survival Analysis with Python](https://www.taylorfrancis.com/books/mono/10.1201/9781003255499/survival-analysis-python-avishek-nag) by Avishek Nag\n",
    "* **[Python Library API]** [SciKit-Survival](https://pypi.org/project/scikit-survival/) by SciKit-Survival Team\n",
    "* **[Python Library API]** [SciKit-Learn](https://scikit-learn.org/stable/index.html) by SciKit-Learn Team\n",
    "* **[Python Library API]** [StatsModels](https://www.statsmodels.org/stable/index.html) by StatsModels Team\n",
    "* **[Python Library API]** [SciPy](https://scipy.org/) by SciPy Team\n",
    "* **[Python Library API]** [Lifelines](https://lifelines.readthedocs.io/en/latest/) by Lifelines Team\n",
    "* **[Kaggle Project]** [Applied Reliability, Solutions To Problems](https://www.kaggle.com/code/keenanzhuo/applied-reliability-solutions-to-problems) by Keenan Zhuo (Kaggle)\n",
    "* **[Kaggle Project]** [Survival Models VS ML Models Benchmark - Churn Tel](https://www.kaggle.com/code/caralosal/survival-models-vs-ml-models-benchmark-churn-tel) by Carlos Alonso Salcedo (Kaggle)\n",
    "* **[Kaggle Project]** [Survival Analysis with Cox Model Implementation](https://www.kaggle.com/code/bryanb/survival-analysis-with-cox-model-implementation/notebook) by Bryan Boulé (Kaggle)\n",
    "* **[Kaggle Project]** [Survival Analysis](https://www.kaggle.com/code/gunesevitan/survival-analysis/notebook) by Gunes Evitan (Kaggle)\n",
    "* **[Kaggle Project]** [Survival Analysis of Lung Cancer Patients](https://www.kaggle.com/code/bryanb/survival-analysis-with-cox-model-implementation/notebook) by Sayan Chakraborty (Kaggle)\n",
    "* **[Kaggle Project]** [COVID-19 Cox Survival Regression](https://www.kaggle.com/code/bryanb/survival-analysis-with-cox-model-implementation/notebook) by Ilias Katsabalos (Kaggle)\n",
    "* **[Kaggle Project]** [Liver Cirrhosis Prediction with XGboost & EDA](https://www.kaggle.com/code/arjunbhaybhang/liver-cirrhosis-prediction-with-xgboost-eda) by Arjun Bhaybang (Kaggle)\n",
    "* **[Article]** [Exploring Time-to-Event with Survival Analysis](https://towardsdatascience.com/exploring-time-to-event-with-survival-analysis-8b0a7a33a7be) by Olivia Tanuwidjaja (Towards Data Science)\n",
    "* **[Article]** [The Complete Introduction to Survival Analysis in Python](https://towardsdatascience.com/the-complete-introduction-to-survival-analysis-in-python-7523e17737e6) by Marco Peixeiro (Towards Data Science)\n",
    "* **[Article]** [Survival Analysis Simplified: Explaining and Applying with Python](https://medium.com/@zynp.atlii/survival-analysis-simplified-explaining-and-applying-with-python-7efacf86ba32) by Zeynep Atli (Towards Data Science)\n",
    "* **[Article]** [Survival Analysis in Python (KM Estimate, Cox-PH and AFT Model)](https://medium.com/the-researchers-guide/survival-analysis-in-python-km-estimate-cox-ph-and-aft-model-5533843c5d5d) by Rahul Raoniar (Medium)\n",
    "* **[Article]** [How to Evaluate Survival Analysis Models)](https://towardsdatascience.com/how-to-evaluate-survival-analysis-models-dd67bc10caae) by Nicolo Cosimo Albanese (Towards Data Science)\n",
    "* **[Article]** [Survival Analysis with Python Tutorial — How, What, When, and Why)](https://pub.towardsai.net/survival-analysis-with-python-tutorial-how-what-when-and-why-19a5cfb3c312) by Towards AI Team (Medium)\n",
    "* **[Article]** [Survival Analysis: Predict Time-To-Event With Machine Learning)](https://towardsdatascience.com/survival-analysis-predict-time-to-event-with-machine-learning-part-i-ba52f9ab9a46) by Lina Faik (Medium)\n",
    "* **[Article]** [A Complete Guide To Survival Analysis In Python, Part 1](https://www.kdnuggets.com/2020/07/complete-guide-survival-analysis-python-part1.html) by Pratik Shukla (KDNuggets)\n",
    "* **[Article]** [A Complete Guide To Survival Analysis In Python, Part 2](https://www.kdnuggets.com/2020/07/guide-survival-analysis-python-part-2.html) by Pratik Shukla (KDNuggets)\n",
    "* **[Article]** [A Complete Guide To Survival Analysis In Python, Part 3](https://www.kdnuggets.com/2020/07/guide-survival-analysis-python-part-3.html) by Pratik Shukla (KDNuggets)\n",
    "* **[Article]** [Model Explainability using SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations)](https://medium.com/@anshulgoel991/model-exploitability-using-shap-shapley-additive-explanations-and-lime-local-interpretable-cb4f5594fc1a) by Anshul Goel (Medium)\n",
    "* **[Article]** [A Comprehensive Guide into SHAP (SHapley Additive exPlanations) Values](https://www.kdnuggets.com/2020/07/guide-survival-analysis-python-part-3.html) by Brain John Aboze (DeepChecks.Com)\n",
    "* **[Article]** [SHAP - Understanding How This Method for Explainable AI Works](https://safjan.com/how-the-shap-method-for-explainable-ai-works/#google_vignette) by Krystian Safjan (Safjan.Com)\n",
    "* **[Article]** [SHAP: Shapley Additive Explanations](https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3) by Fernando Lopez (Medium)\n",
    "* **[Article]** [Explainable Machine Learning, Game Theory, and Shapley Values: A technical review](https://www.kdnuggets.com/2020/07/guide-survival-analysis-python-part-3.html) by Soufiane Fadel (Statistics Canada)\n",
    "* **[Article]** [SHAP Values Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30) by Samuele Mazzanti (Towards Data Science)\n",
    "* **[Article]** [Explaining Machine Learning Models: A Non-Technical Guide to Interpreting SHAP Analyses](https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/) by Aidan Cooper (AidanCooper.Co.UK)\n",
    "* **[Article]** [Shapley Additive Explanations: Unveiling the Black Box of Machine Learning](https://python.plainenglish.io/shapley-additive-explanations-unveiling-the-black-box-of-machine-learning-477ba01ffa07) by Evertone Gomede (Medium)\n",
    "* **[Article]** [SHAP (SHapley Additive exPlanations)](https://www.nerd-data.com/shap/) by Narut Soontranon (Nerd-Data.Com)\n",
    "* **[Article]** [Survival Analysis](https://quantdev.ssri.psu.edu/resources/survival-analysis) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Part 1: How to Format Data for Several Types of Survival Analysis Models](https://quantdev.ssri.psu.edu/tutorials/part-1-how-format-data-several-types-survival-analysis-models) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Part 2: Single-Episode Cox Regression Model with Time-Invariant Predictors](https://quantdev.ssri.psu.edu/tutorials/part-2-single-episode-cox-regression-model-time-invariant-predictors) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Part 3: Single-Episode Cox Regression Model with Time-Varying Predictors](https://quantdev.ssri.psu.edu/tutorials/part-3-single-episode-cox-regression-model-time-varying-predictors) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Part 4: Recurring-Episode Cox Regression Model with Time-Invariant Predictors](https://quantdev.ssri.psu.edu/tutorials/part-4-recurring-episode-cox-regression-model-time-invariant-predictors) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Part 5: Recurring-Episode Cox Regression Model with Time-Varying Predictors](https://quantdev.ssri.psu.edu/tutorials/part-5-recurring-episode-cox-regression-model-time-varying-predictors) by Jessica Lougheed and Lizbeth Benson (QuantDev.SSRI.PSU.Edu)\n",
    "* **[Article]** [Parametric Survival Modeling](https://devinincerti.com/2019/06/18/parametric_survival.html) by Devin Incerti (DevinIncerti.Com)\n",
    "* **[Article]** [Survival Analysis Simplified: Explaining and Applying with Python](https://medium.com/@zynp.atlii/survival-analysis-simplified-explaining-and-applying-with-python-7efacf86ba32) by Zeynep Atli (Medium)\n",
    "* **[Article]** [Understanding Survival Analysis Models: Bridging the Gap between Parametric and Semiparametric Approaches](https://medium.com/@zynp.atlii/understanding-survival-analysis-models-bridging-the-gap-between-parametric-and-semiparametric-923cdcfc9f05) by Zeynep Atli (Medium)\n",
    "* **[Article]** [Survival Modeling — Accelerated Failure Time — XGBoost](https://towardsdatascience.com/survival-modeling-accelerated-failure-time-xgboost-971aaa1ba794) by Avinash Barnwal (Medium)\n",
    "* **[Publication]** [Regression Models and Life Tables](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1972.tb00899.x) by David Cox (Royal Statistical Society)\n",
    "* **[Publication]** [Covariance Analysis of Censored Survival Data](https://pubmed.ncbi.nlm.nih.gov/4813387/) by Norman Breslow (Biometrics)\n",
    "* **[Publication]** [The Efficiency of Cox’s Likelihood Function for Censored Data](https://www.jstor.org/stable/2286217) by Bradley Efron (Journal of the American Statistical Association)\n",
    "* **[Publication]** [Regularization Paths for Cox’s Proportional Hazards Model via Coordinate Descent](https://doi.org/10.18637/jss.v039.i05) by Noah Simon, Jerome Friedman, Trevor Hastie and Rob Tibshirani (Journal of Statistical Software)\n",
    "* **[Publication]** [Shapley Additive Explanations](https://dl.acm.org/doi/10.5555/1756006.1756007) by Noah Simon, Jerome Friedman, Trevor Hastie and Rob Tibshirani (Journal of Statistical Software) by Erik Strumbelj and Igor Kononenko (The Journal of Machine Learning Research)\n",
    "* **[Publication]** [A Unified Approach to Interpreting Model Predictions](https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) by Scott Lundberg and Sun-In Lee (Conference on Neural Information Processing Systems)\n",
    "* **[Publication]** [Survival Analysis Part I: Basic Concepts and First Analyses](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/) by Taane Clark (British Journal of Cancer)\n",
    "* **[Publication]** [Survival Analysis Part II: Multivariate Data Analysis – An Introduction to Concepts and Methods](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394368/) by Mike Bradburn (British Journal of Cancer)\n",
    "* **[Publication]** [Survival Analysis Part III: Multivariate Data Analysis – Choosing a Model and Assessing its Adequacy and Fit](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2376927/) by Mike Bradburn (British Journal of Cancer)\n",
    "* **[Publication]** [Survival Analysis Part IV: Further Concepts and Methods in Survival Analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394469/) by Taane Clark (British Journal of Cancer)\n",
    "* **[Publication]** [Marginal Likelihoods Based on Cox's Regression and Life Model](https://www.jstor.org/stable/2334538) by Jack Kalbfleisch and Ross Prentice (Biometrika)\n",
    "* **[Publication]** [Hazard Rate Models with Covariates](https://www.jstor.org/stable/2529934) by Jack Kalbfleisch and Ross Prentice (Biometrics)\n",
    "* **[Publication]** [Linear Regression with Censored Data](https://www.jstor.org/stable/2335161) by Jonathan Buckley and Ian James (Biometrika)\n",
    "* **[Publication]** [A Statistical Distribution Function of Wide Applicability](https://www.semanticscholar.org/paper/A-Statistical-Distribution-Function-of-Wide-Weibull/88c37770028e7ed61180a34d6a837a9a4db3b264) by Waloddi Weibull (Journal of Applied Mechanics)\n",
    "* **[Publication]** [Exponential Survivals with Censoring and Explanatory Variables](https://www.jstor.org/stable/2334539) by Ross Prentice (Biometrika)\n",
    "* **[Publication]** [The Lognormal Distribution, with Special Reference to its Uses in Economics](https://www.semanticscholar.org/paper/The-Lognormal-Distribution%2C-with-Special-Reference-Corlett-Aitchison/1f59c53ff512fa77e7aee5e6d98b1786c2aaf129) by John Aitchison and James Brown (Economics Applied Statistics)\n",
    "* **[Course]** [Survival Analysis in Python](https://app.datacamp.com/learn/courses/survival-analysis-in-python) by Shae Wang (DataCamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af14bfb0-22ee-4482-8df6-5854be5ca81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.rendered_html { font-size: 15px; font-family: 'Trebuchet MS'; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.rendered_html { font-size: 15px; font-family: 'Trebuchet MS'; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
